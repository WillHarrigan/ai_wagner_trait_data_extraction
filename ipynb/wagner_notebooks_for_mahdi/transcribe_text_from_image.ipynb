{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install marker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Notes for Mahdi: \n",
    "\n",
    "1. The following notebook is how I am extracting text from the .jpeg/.pdf photographs of the Wagner text\n",
    "2. The version of python I am using = Python 3.10.13\n",
    "3. Transcriptions are done in 3 parts:\n",
    "    A. Extract text from a PDF containing a batch of Wagner passages using Marker\n",
    "    B. Extract text individually from .jpeg version of Wagner passages using Base64 and LLMs\n",
    "    C. Use LLM to synthesize both transcriptions\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages\n",
    "import glob\n",
    "import tqdm\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "## Marker (OCR library) Packages\n",
    "from marker.config.parser import ConfigParser\n",
    "from marker.converters.pdf import PdfConverter\n",
    "from marker.models import create_model_dict\n",
    "from marker.output import text_from_rendered\n",
    "import cgi\n",
    "\n",
    "## OCR on base64 packages\n",
    "import base64\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import get_args, Literal, Union\n",
    "\n",
    "# LLM/Agent packages\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent\n",
    "from openai.types.chat.chat_completion_content_part_param import (\n",
    "    ChatCompletionContentPartTextParam,\n",
    "    ChatCompletionContentPartImageParam\n",
    ")\n",
    "from openai.types.chat.chat_completion_content_part_image_param import (\n",
    "    ImageURL\n",
    ")\n",
    "import pydantic_ai.models as ai_models\n",
    "\n",
    "# Directory to photo training set\n",
    "photo_dir = \"../../training_set/\"\n",
    "\n",
    "## To import API keys\n",
    "import sys\n",
    "sys.path.append('/Users/williamharrigan/Desktop/')\n",
    "\n",
    "# Script containing API keys\n",
    "import api_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marker photo:  ../../training_set/test_passage_wagner_batch.pdf\n",
      "Base64/OCR photo:  ../../training_set/Acanthaceae_Dicliptera_chinensis.jpeg\n"
     ]
    }
   ],
   "source": [
    "## Path to .jpeg photos of Wagner passages\n",
    "jpeg_files = glob.glob(f'{photo_dir}/*.jpeg')\n",
    "\n",
    "## Path to .pdf version of batch of Wagner photos\n",
    "wagner_pdf_batch = glob.glob(f'{photo_dir}/test*.pdf')[0] # test batch contains 2 photos -> complete batch contains 50 photos\n",
    "# wagner_pdf_batch = glob.glob(f'{photo_dir}/complete*.pdf')[0]\n",
    "print('Marker photo: ', wagner_pdf_batch)\n",
    "\n",
    "# Sort files to process alphabetically\n",
    "sorted_files = sorted(jpeg_files)\n",
    "print('Base64/OCR photo: ', sorted_files[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marker OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded layout model s3://layout/2025_02_18 on device mps with dtype torch.float16\n",
      "Loaded texify model s3://texify/2025_02_18 on device mps with dtype torch.float16\n",
      "Loaded recognition model s3://text_recognition/2025_02_18 on device mps with dtype torch.float16\n",
      "Loaded table recognition model s3://table_recognition/2025_02_18 on device mps with dtype torch.float16\n",
      "Loaded detection model s3://text_detection/2025_02_28 on device mps with dtype torch.float16\n",
      "Loaded detection model s3://inline_math_detection/2025_02_24 on device mps with dtype torch.float16\n"
     ]
    }
   ],
   "source": [
    "## Set configuration for Marker text extraction\n",
    "\n",
    "# Sets LLM component to use Gemini, but can use any available LLM\n",
    "config = {\n",
    "    \"output_format\": \"json\",\n",
    "    \"use_llm\": True,\n",
    "    \"gemini_api_key\": os.environ[\"GEMINI_API_KEY\"], # API key\n",
    "    \"gemini_model\": \"gemini-2.5-pro-preview-03-25\", # LLM\n",
    "    \"llm_service\": \"marker.services.gemini.GoogleGeminiService\" # Set for converter\n",
    "}\n",
    "\n",
    "# Image parser\n",
    "config_parser = ConfigParser(config)\n",
    "\n",
    "# Default parameters for Marker OCR\n",
    "converter = PdfConverter(\n",
    "    config=config_parser.generate_config_dict(),\n",
    "    artifact_dict=create_model_dict(),\n",
    "    processor_list=config_parser.get_processors(),\n",
    "    renderer=config_parser.get_renderer(),\n",
    "    llm_service=config[\"llm_service\"]  # Set in config (above)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing layout: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]\n",
      "LLM layout relabelling: 4it [00:03,  1.26it/s]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s]\n",
      "Detecting bboxes: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]\n",
      "Recognizing Text: 100%|██████████| 2/2 [00:12<00:00,  6.14s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "LLMTableMergeProcessor running: 0it [00:00, ?it/s]\n",
      "LLM processors running: 100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "## Run Marker OCR on batch -> output in .json format\n",
    "\n",
    "rendered = converter(wagner_pdf_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plant: Acanthaceae_Dicliptera_chinensis\n",
      "Marker Extracted Text:\n",
      "['(nat)', '[Justicia chinensis L.]', '1. Dicliptera chinensis (L.) Juss.', 'Sprawling or decumbent perennial herbs; stems 2-7 dm long. Leaves green, lower surface slightly paler, ovate, 2.5-13.5 cm long, sparsely strigillose, especially on the veins, cystoliths prominent on upper surface as white raised streaks the size of the hairs, petioles 1-3.5 cm long. Flowers in axillary cymes, each one subtended by 2 green, ovate bracts of unequal size, the', 'larger one ca. 12-14 mm long, the smaller\\nPlate 1. one ca. 8-9 mm long, all bracts short-vil-', '', \"lous especially along the margins, the veins inconspicuous, pedicels 0-1 mm long; calyx lobes of unequal size, 5-7 mm long; corolla rose to purple, the throat with purple spots, 5-13 mm long. Capsules ovoid, 6-7 mm long, short-villous. Seeds 4, discoid. Native to tropical areas worldwide; in Hawai'i naturalized primarily in or near urban areas, at least on Kaua'i and O'ahu, but perhaps more widespread. Pope (1929) states that this plant was recently introduced to Hawai'i. First naturalized collection made on O'ahu in 1942 (Caum s.n., BISH) .-\", '', '', '']\n",
      "\n",
      "Plant: Acanthaceae_Ruellia_simplex\n",
      "Marker Extracted Text:\n",
      "['', '(nat)', '1. Ruellia brittoniana E. Leonard', \"This species is sometimes confused with Ruellia malacosperma Greenm., which does not occur in Hawai'i, and differs from R. brittoniana in having shorter lanceolate leaves and pilose pubescence.\", \"Erect perennial herbs; lower stems sometimes becoming somewhat woody, 0.5-1 m long. Leaves linear-elliptic to linear-lanceolate, 8-22 cm long, 0.8-1.5 cm wide, glabrate, petioles 10-24 mm long. Flowers in cymose panicles, each flower subtended by 2 linear bracts 3-7 mm long; calyx lobes 5, linear, 8-12 mm long; corolla lavender, the throat purple, 4-4.5 cm long. Capsules ellipsoid, 2-2.5 cm long, glabrous. [2n = 34.] Native to Mexico; in Hawai'i cultivated as an ornamental but easily escaping, now naturalized and often found in dry habitats such as cracks in sidewalks and disturbed, shaded gulch bottoms, on Midway Atoll, Kaua'i, and O'ahu. First collected on O'ahu in 1930 (St. John 10515, BISH) .-Plate 2.\", '']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Processing Marker Text Extractions\n",
    "\n",
    "# Store marker text extractions\n",
    "marker_ocr_outputs = {}\n",
    "\n",
    "# Iterate through rendered passages\n",
    "for i in range(len(rendered.children)):\n",
    "    \n",
    "    plant_species = sorted_files[i].split('/')[-1].strip('.jpeg')\n",
    "    print(f\"Plant: {plant_species}\")\n",
    "    \n",
    "    # Extract all text blocks from rendered\n",
    "    blocks = rendered.children[i].children\n",
    "\n",
    "    # Reorder extracted Wagner text using BeautifulSoup\n",
    "    block_list = []\n",
    "    for block in blocks:\n",
    "        text = BeautifulSoup(block.html, \"html.parser\").get_text()\n",
    "        block_list.append({\n",
    "            \"text\": text.strip(),\n",
    "            \"x\": block.bbox[2],  # left coordinate\n",
    "            \"y\": block.bbox[3]   # top coordinate\n",
    "        })\n",
    "        \n",
    "    block_list.sort(key=lambda b: (b[\"x\"], b[\"y\"]))\n",
    "\n",
    "    print('Marker Extracted Text:')\n",
    "\n",
    "    # Concatenate Text\n",
    "    total = []\n",
    "\n",
    "    for block in block_list:\n",
    "        total.append(block[\"text\"])\n",
    "    \n",
    "    # Save to dictionary\n",
    "    marker_ocr_outputs[plant_species] = total\n",
    "    print(f\"{total}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base64 OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async transcription function\n",
    "async def transcribe_image_with_openai(image_path: str) -> str:\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    agent = Agent(\n",
    "        model=\"openai:gpt-4o\",\n",
    "        result_type=str,\n",
    "        system_prompt=\"You are a vision model capable of accurately performing OCR on an image\",\n",
    "    )\n",
    "\n",
    "    image_param = ChatCompletionContentPartImageParam(\n",
    "        type='image_url',\n",
    "        image_url=ImageURL(url=f\"data:image/png;base64,{base64_image}\", detail='low')\n",
    "    )\n",
    "\n",
    "    message = [\n",
    "        ChatCompletionContentPartTextParam(\n",
    "            type=\"text\",\n",
    "            text=\"Convert the image to text. Don't miss any text and DO NOT ADD ANY TEXT that is not present in the image.\"\n",
    "        ),\n",
    "        image_param\n",
    "    ]\n",
    "\n",
    "    response = await agent.run(message)\n",
    "    return response.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run base64 OCR on .jpeg images of Wagner Passages\n",
    "\n",
    "# Storage for Extracted Text\n",
    "openai_transcriptions = {}\n",
    "\n",
    "# Plant ID = format files are saved in = family_genus_species.jpeg\n",
    "plant_id = 'Acanthaceae_Dicliptera_chinensis'\n",
    "\n",
    "# Set image path\n",
    "image_path = f\"{photo_dir}/{plant_id}.jpeg\"\n",
    "\n",
    "# Run transcription agent\n",
    "openai_transcriptions[plant_id] = await transcribe_image_with_openai(image_path)\n",
    "\n",
    "## Loop to process all Wagner .jpeg images\n",
    "\n",
    "# for image_path in tqdm.tqdm(jpeg_files):\n",
    "#     plant_id = image_path.split('/')[-1].strip('.jpeg') \n",
    "#     openai_transcriptions[plant_id] = await transcribe_image_with_openai(image_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Agent to Synthesize base64 and Marker text extractions\n",
    "\n",
    "create_final_transcription = Agent(\n",
    "    model=\"openai:gpt-4o\",\n",
    "    result_type=str,\n",
    "    system_prompt=(\n",
    "        \"You are a botanical plant expert. Given two OCR outputs of the same passage on Hawaiian plants, merge them into one accurate, complete transcription. Choose the most reliable text from each version.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.01s/it]\n"
     ]
    }
   ],
   "source": [
    "# Dictionary for final transcriptions\n",
    "synthesized_transcriptions = {}\n",
    "\n",
    "# Iterate through available transcriptions (jpeg_files, openai_transcriptions or marker_ocr_outputs)\n",
    "for plant_id in tqdm.tqdm(openai_transcriptions.keys()): \n",
    "\n",
    "    # Get transcriptions from dictionary\n",
    "    ocr_1 = openai_transcriptions[plant_id]\n",
    "    ocr_2 = marker_ocr_outputs[plant_id]\n",
    "\n",
    "    # Input to LLM\n",
    "    og_transcriptions = f\"\"\" Here are the following two passages. It is very important to include page number and any other relevant information. Do not add any information that is not present in the transcriptions.\n",
    "    OCR text 1:\n",
    "    {ocr_1}\n",
    "\n",
    "    OCR text 2:\n",
    "    {ocr_2}\n",
    "    \"\"\"\n",
    "\n",
    "    # Run LLM-agent to get synthesized Wagner passage text\n",
    "    r = await create_final_transcription.run(og_transcriptions)\n",
    "    \n",
    "    # Save to dictionary\n",
    "    synthesized_transcriptions[plant_id] = r.data\n",
    "    \n",
    "    \n",
    "# Save file to pkl\n",
    "# with open('wagner_transcriptions.pkl', 'wb') as f:\n",
    "#     pkl.dump(synthesized_transcriptions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acanthaceae_Dicliptera_chinensis\n",
      "---\n",
      "\n",
      "171\n",
      "\n",
      "1. Dicliptera chinensis (L.) Juss. [Justicia chinensis L.] (nat)\n",
      "\n",
      "Sprawling or decumbent perennial herbs; stems 2-7 dm long. Leaves green, lower surface slightly paler, ovate, 2.5-13.5 cm long, sparsely strigillose, especially on the veins, cystoliths prominent on upper surface; white raised streaks the size of the larger petals, 1-3.5 cm long. Flowers in axillary cymes, each one subtended by 2 green, ovate bracts of unequal size, the larger one ca. 12-14 mm long, the smaller one ca. 8-9 mm long, all bracts short-villous especially along the margins, the veins inconspicuous, pedicels 0.7-1 mm long; calyx lobes of unequal size, 5-17 mm long; corolla conspicuous, rose to purple, the throat with purple spot, 5-13 mm long. Capsules ovoid, 6-7 mm long, short-villous. Seeds 4, discoid. Native to tropical areas worldwide; in Hawai'i naturalized on O'ahu; in moist disturbed areas, at least on Kaua'i and O'ahu, but perhaps more widespread. Popenoe (1929) states that this plant was recently introduced to Hawai'i. First known collection made by Obo in 1942 (Caum s.n., BISH; Plate 1, Fig. 3).\n"
     ]
    }
   ],
   "source": [
    "for key, value in synthesized_transcriptions.items():\n",
    "    print(key)\n",
    "    print(value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
